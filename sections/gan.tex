\section{Generative Adversarial Networks}

Learning reusable resource representations from large datasets has been an active research area. One way to build good image representations is through Generative Adversarial Networks. Generator Adverse Networks (GAN) learn to synthesize elements of a target distribution using two competing neural networks. GAN networks can produce compelling images that are sharper than those produced by automatic encoders using pixel losses. The Generator (G) network selects an n-dimensional random sample from a predefined distribution, conventionally called latent space and attempts to create examples of the target distribution. The discriminant network (D) takes a generated or real example as input and has to make the binary decision whether the input is real or generated. This competition process is expressed as a zero-sum game in the following loss term:

Let x be a natural image taken from a distribution, $ p_X$ and be a random vector \textit{z} in $ {\rm I\!R}^d $. Considering that z is of a uniform distribution with the support $[1-1]^d$, then \textit{g} and \textit{f} are the generator and discriminative models, respectively. Denoting the distribution \textit{g(z)} to $ p_G $. The discriminative model estimates the probability that an input image was generated by $ p_X $. Ideally, \textit{f(x)=1}  if $x  \sim\  p_X$ and \textit{f (x) = 0} if $ x \sim\ p_G $. A generator network corresponds to a mini-game with two players, the generator and discriminative models, trained according to the equation \cite{Liu2016}:


\begin{equation}
\medmath{ \underset{g}{max} \underset{f}{min} V(f,g)= \mathbb{E}_{x \sim px} [-log(f(x))]+\mathbb{E}_{z \sim pz}[-log(1-f(g(z)))]} 
\end{equation}


The equation is solved by applying the gradient in two steps:

\begin{equation}
\theta^{t+1}_{f} = \theta^{t}_{f} -\lambda^t \nabla_{\theta f} V (f^t, g^t)
\end{equation}

\begin{equation}
\theta^{t+1}_{g} = \theta^{t}_{g} -\lambda^t \nabla_{\theta g} V (f^t+1, g^t)
\end{equation}


$ \theta_f $ and $ \theta_g $ are parameters of f and g, $ \ lambda $ is the learning rate and t is the number of iterations.

Goodfellow et al. show that given sufficient capacity for f and g training iterations, the distribution $ p_G $ converges to $ p_X $. In other words, from a random vector z, the network g can synthesize an image g (z) that resembles one that is extracted from the true distribution $ p_X $. \cite{Goodfellow2014}.

Building a good generative model of natural images has been a fundamental problem. However, images are complex and high dimensional, making them hard to model well. Generative Adversarial Networks \cite{Goodfellow2014} generated images suffering from being noisy and incomprehensible. A laplacian pyramid extension to this approach showed higher quality images, but they still suffered from the objects looking wobbly because of noise introduced in chaining multiple models \cite{Denton2015}. A recurrent network approach \cite{gregor2015draw} and a deconvolution network approach (Dosovitskiy et al., 2014) have also recently had some success with generating natural images. However, they have not leveraged the generators for supervised tasks.

Radford et al.  introduce a new class of CNNs called deep convolutional generative adversarial networks (DCGANs) \cite{Radford2015UnsupervisedNetworks}. The main differences of DCGANS are: Convert max-pooling layers to convolution layers; Convert fully connected layers to global average pooling layers in the discriminator; Use batch normalization layers in the generator and the discriminator and use leaky ReLU activation functions in the discriminator.