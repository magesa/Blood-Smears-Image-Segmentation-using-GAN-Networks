\section{Generative Adversarial Networks}

Learning reusable resource representations from large datasets has been an active research area. One way to build good image representations is through Generative Adversarial Networks. Generator Adverse Networks (GAN) learn to synthesize elements of a target distribution using two competing neural networks. GAN networks can produce compelling images that are sharper than those produced by automatic encoders using pixel losses. The Generator (G) network selects an n-dimensional random sample from a predefined distribution, conventionally called latent space and attempts to create examples of the target distribution. The discriminant network (D) takes a generated or real example as input and has to make the binary decision whether the input is real or generated. This competition process is expressed as a zero-sum game in the following loss term:

Let x be a natural image taken from a distribution, $ p_X$ and be a random vector \textit{z} in $ {\rm I\!R}^d $. Considering that z is of a uniform distribution with the support $[1-1]^d$, then \textit{g} and \textit{f} are the generator and discriminative models, respectively. Denoting the distribution \textit{g(z)} to $ p_G $. The discriminative model estimates the probability that an input image was generated by $ p_X $. Ideally, \textit{f(x)=1}  if $ x \ yes \ p_X $ and \ textit {f (x) = 0} if $ x \ yes \ p_G $. A generator network corresponds to a mini-game with two players, the generator and discriminative models, trained according to the equation \cite{Liu2016}:


\begin{equation}
\medmath{ \underset{g}{max} \underset{f}{min} V(f,g)= \mathbb{E}_{x \sim px} [-log(f(x))]+\mathbb{E}_{z \sim pz}[-log(1-f(g(z)))]} 
\end{equation}


The equation is solved by applying the gradient in two steps:

\begin{equation}
\theta^{t+1}_{f} = \theta^{t}_{f} -\lambda^t \nabla_{\theta f} V (f^t, g^t)
\end{equation}

\begin{equation}
\theta^{t+1}_{g} = \theta^{t}_{g} -\lambda^t \nabla_{\theta g} V (f^t+1, g^t)
\end{equation}